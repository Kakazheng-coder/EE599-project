# -*- coding: utf-8 -*-
"""AWS1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vWLjHM7jfowzCwUQTQQNaUAOuE1RJkJp
"""

import os
import sys
import numpy as np
import matplotlib.image as img
from os.path import isfile, join
import numpy as np
import collections
from torchvision import transforms
import torch
from PIL import Image
from torch.utils.data import Dataset, DataLoader
import os.path as osp
import csv
from sklearn.model_selection import train_test_split
import torch.nn as nn
import torch.nn.functional as F
from SENET import senet154
import matplotlib.pyplot as plt
import torchvision
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter 
from tqdm import tqdm

from SGLA import SGLANetwork

num_epochs = 30
image_root_train = './train_set'
image_root_test = './val_set'
meta_root = './class_list.txt'
debug = False
train_annotations = "./train_labels.csv"
test_annotations = "./val_labels.csv"
batch = 16

def label_with_index(meta_root): #build dictionary between label name and it's number by one-hot encode
  class_to_ix = {} #{label_name: index}
  ix_to_class = {} #{index: label_name}
  data_txt = open(meta_root, 'r')
  classes = []
  index = []
  for line in data_txt:
      line = line.strip()
      words = line.split()
      classes.append(words[1])
      index.append(words[0])
  ix_to_class = dict(zip(range(len(classes)), classes))
  class_to_ix = {v: k for k, v in ix_to_class.items()}
  return class_to_ix,ix_to_class


def create_dataset(file1,file2, image_root_train, image_root_test):
  train_images = []
  train_labels = []
  test_images = []
  test_labels = []

  with open(file1, "r") as csv_file:
      csv_reader = csv.reader(csv_file, delimiter=',')
      next(csv_reader)
      for lines in csv_reader:
        train_images.append(lines[0]) 
        train_labels.append(int(lines[1]))
  train_info = dict(zip(train_images, train_labels))
  files_train = os.listdir(image_root_train)
  X_train = []; y_train = []
  for a in files_train:
      X_train.append(a)
      y_train.append(train_info[a])

  # y = LabelEncoder().fit_transform(y)
  # split dataset
  # X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)
 # print('len of X_train: {}, # of categories: {}'.format(len(X_train), max(y) + 1))

  with open(file2, "r") as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    next(csv_reader)
    for lines in csv_reader:
      test_images.append(lines[0]) 
      test_labels.append(int(lines[1])) 
  test_info = dict(zip(test_images, test_labels))
  files_test = os.listdir(image_root_test)
  X_test = []; y_test = []
  for b in files_test:
      X_test.append(b)
      y_test.append(test_info[b])
  # return X_train, X_val, X_test, y_train, y_val, y_test, max(y) + 1
  return X_train, X_test, y_train, y_test, max(y_train) + 1

# # For category classification
class trainset(torch.utils.data.Dataset):
    def __init__(self, X_train, y_train, transform):
        self.X_train = X_train
        self.y_train = y_train
        self.transform = transform
        self.image_dir = image_root_train

    def __len__(self):
        return len(self.X_train)

    def __getitem__(self, item):
        file_path = osp.join(self.image_dir, self.X_train[item])
        return self.transform(Image.open(file_path)),self.y_train[item]




class testset(torch.utils.data.Dataset):
    def __init__(self, X_test, y_test, transform):
        self.X_test = X_test
        self.y_test = y_test
        self.transform = transform
        self.image_dir = image_root_test


    def __len__(self):
        return len(self.X_test)


    def __getitem__(self, item):
        file_path = osp.join(self.image_dir, self.X_test[item])
        return self.transform(Image.open(file_path)), self.y_test[item]

def get_data_transforms():
    data_transforms = {
        'train': transforms.Compose([
            transforms.Resize((255,255)),
            transforms.ToTensor(),
            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
        ]),
        'test': transforms.Compose([
            transforms.Resize((255,255)),
            transforms.ToTensor(),
            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
        ]),
    }
    return data_transforms

def get_dataloader(debug, image_root_train, image_root_test):

    # X_train, X_val, X_test, y_train, y_val, y_test, classes = create_dataset(train_annotations,test_annotations, image_root_train, image_root_test)
    X_train, X_test, y_train, y_test, classes = create_dataset(train_annotations,test_annotations, image_root_train, image_root_test)
    transforms = get_data_transforms()
    if debug==True:
        train_set = trainset(X_train[:80], y_train[:80], transform=transforms['train'])
        # val_set = testset(X_val[:80], y_val[:80], transform=transforms['test'])
        test_set = testset(X_test[:10], y_test[:10], transform=transforms['test'])
        dataset_size = {'train': len(y_train), 'test': len(y_test)}
    else:
        train_set = trainset(X_train, y_train, transforms['train'])
        test_set = testset(X_test, y_test, transforms['test'])
        dataset_size = {'train': len(y_train), 'test': len(y_test)}

    return train_set, test_set, classes, dataset_size

class_to_ix,ix_to_class = label_with_index(meta_root)
train_set, test_set, classes, dataset_size = get_dataloader(debug, image_root_train, image_root_test)

split_ratio=0.8 #80-20 train/validation split 
length_train=int(split_ratio*len(train_set)) #number of training samples 
length_valid=len(train_set)-length_train 

trainset, valset = torch.utils.data.random_split(train_set, [length_train, length_valid])

# Declaring the train validation and test loaders
#shuffle enabled as True for the train dataloader
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch,
                                        shuffle=True)

#shuffle enabled as False for the valid dataloader
valloader = torch.utils.data.DataLoader(valset, batch_size=batch,
                                        shuffle=False) 

#shuffle enabled as False for the test dataloader
testloader = torch.utils.data.DataLoader(test_set, batch_size=batch,
                                        shuffle=False) 

# inspecting the length of datasets (test and train datasets)
num_train_samples=len(trainset)
print("Train:",num_train_samples)  
num_test_samples=len(test_set)
print("Test:",num_test_samples)  
num_val_samples=len(valset)
print("Valid:", num_val_samples)  

inputs, labels = next(iter(trainloader)) #generate a single batch from trainloader 
print(len(trainloader)) #number of batches 
print(inputs.size())
print("done")




import torchvision.transforms as transforms

# Testing function
def eval_model(model,loader,criterion,device):
    """model: instance of model class 
       loader: test dataloader
       criterion: loss function
       device: CPU/GPU
    """
    model.eval() #needed to run the model in eval mode to freeze all the layers
    correct=0
    total=0
    total_loss=0
    predlist=torch.zeros(0,dtype=torch.long, device='cpu')
    lbllist=torch.zeros(0,dtype=torch.long, device='cpu')
    with torch.no_grad():
        total=0
        correct=0
        for idx,(inputs,labels) in enumerate(loader):
            inputs=inputs.to(device)
            labels=labels.to(device)
            out, global_out, local_out = model(inputs)
            out=F.softmax(out,dim=1)
        global_out = F.softmax(global_out,dim=1)
        local_out = F.softmax(local_out, dim = 1)
        loss_global = criterion(global_out, labels)
        loss_local = criterion(local_out, labels)
        loss_out = criterion(out,labels)
        val_loss = loss_out + 0.5*loss_global + 0.5*loss_local
        total_loss=total_loss+val_loss
        preds=torch.max(out,dim=1)[1]
        
        # Append batch prediction results
        predlist=torch.cat([predlist,preds.view(-1).cpu()])
        lbllist=torch.cat([lbllist,labels.view(-1).cpu()])
        correct=correct+(preds==labels).cpu().sum().numpy() 
        total=total+len(labels)
    Accuracy=100*(correct/total)
    fin_loss=total_loss/(len(loader))
    
    return(Accuracy,  fin_loss,  predlist, lbllist)

#defining loss and optimizer
model = SGLANetwork()
criterion = nn.CrossEntropyLoss()   # includes softmax for this criterion
initial_learning_rate = 0.0001
optimizer = optim.Adam(model.parameters(), lr=initial_learning_rate, weight_decay = 0.01) # weight decay adds L2 optimizer
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1);  # learning rate schedular
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
iter_count = 0

model=model.to(device)
train_loss_list=[]
train_acc_list=[]
val_loss_list=[]
val_acc_list=[]
best_val_acc=0

for i in np.arange(num_epochs): #outer loop 
    train_loss=0.0
    correct=0
    for idx,(inputs,labels) in enumerate(tqdm(trainloader, desc=f'Epoch {i+1:02d}')):
        iter_count += 1
        
        #sending inputs and labels to device 
        inputs=inputs.to(device)
        labels=labels.to(device)
        
        #zero out the gradients to avoid any accumulation during backprop
        optimizer.zero_grad()
        
        #forward pass through the network
        out, global_out, local_out = model(inputs) #batch_size x 10
        
        #compute the loss between ground truth labels and outputs
        loss_global = criterion(global_out, labels)
        loss_local = criterion(local_out, labels)
        loss_out = criterion(out,labels)
        loss = loss_out + 0.5*loss_global + 0.5*loss_local
        
        loss.backward() #computes derivative of loss for every variable (gradients)
        optimizer.step() #optimizer updates based on gradients 
        
        preds=torch.max(out,dim=1)[1] # obtaining the predicted class (dimension of outputs is batch_size x number of classes)
        correct=correct+(preds==labels).cpu().sum().numpy() #.cpu() transfers tensors from GPU to CPU
        train_loss=train_loss+loss.item()    
        
    train_loss=train_loss/len(trainloader) #computing the total loss for the entire training set
    train_accuracy=100*(correct/len(trainloader.dataset)) #train accuracy for the dataset
    val_accuracy,val_loss,  predlist, lbllist =eval_model(model,valloader,criterion,device) #validation accuracy, validation loss for the entire validation set  

    
    train_loss_list.append(train_loss)
    train_acc_list.append(train_accuracy)
    val_loss_list.append(val_loss)
    val_acc_list.append(val_accuracy)
    model.train(True)
    print('Epoch:%d,Train Loss:%f,Training Accuracy:%f,Validation Accuracy:%f'%(i+1,train_loss,train_accuracy,val_accuracy))
    if(val_accuracy > best_val_acc):
        print('Saving the best model')
        best_val_acc=val_accuracy
        torch.save({
            'epoch': i+1,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': train_loss}, 'best_model.pth') #saving all the required information in .pth file (required for restarting models later)        

plt.figure()
plt.plot(np.arange(num_epochs), train_loss_list, label='Training loss')
plt.plot(np.arange(num_epochs), val_loss_list, label='Validation_loss')
plt.xlabel('epochs')
plt.ylabel('Multiclass Cross Entropy Loss')
plt.legend()
plt.savefig('./Loss.png', dpi=256)

plt.figure()
plt.plot(np.arange(num_epochs), np.array(train_acc_list)/100, label='Training accuracy')
plt.plot(np.arange(num_epochs), np.array(val_acc_list)/100, label='Validation accuracy')
plt.xlabel('epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.savefig('./Accuracy.png', dpi=256)


#saving the entire model 
torch.save(model,'model.pth')

### loading the saved entire model 
model_total=torch.load('model.pth')

### loading the saved best model with state dict 

best_model=model #declare the model class 
checkpoint=torch.load('best_model.pth')
best_model.load_state_dict(checkpoint['model_state_dict'])

##inference with the saved entire model 
model_total.eval()
test_accuracy_total, test_loss_total, predlist, lbllist = eval_model(model_total,testloader,criterion,device)
print('Test accuracy using the entire saved model:%f' %(test_accuracy_total))
print('Test loss using the entire saved model:%f' %(test_loss_total))

##inference with the best model loaded from state dict
best_model.eval()
test_accuracy_best, test_loss_best, predlist, lbllist = eval_model(best_model,testloader,criterion,device)
print('Test accuracy using the best saved model:%f' %(test_accuracy_best))
print('Test loss using the best saved model:%f' %(test_loss_best))
